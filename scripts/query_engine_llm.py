from sentence_transformers import SentenceTransformer
import faiss
import pickle
from pathlib import Path
from ollama import Client
import tiktoken

INDEX_PATH = Path("vector_store/faiss.index")
META_PATH = Path("vector_store/metadata.pkl")
MAX_TOKENS = 1500

ollama = Client(host="http://localhost:11434")
embedder = SentenceTransformer('intfloat/multilingual-e5-base')
index = faiss.read_index(str(INDEX_PATH))
enc = tiktoken.get_encoding("cl100k_base")

with META_PATH.open("rb") as f:
    metadata = pickle.load(f)


def count_tokens(text: str) -> int:
    return len(enc.encode(text))

def rerank(query: str, candidates: list[dict], top_k: int = 5) -> list[dict]:
    scored = []
    system_prompt = (
        "–¢—ã ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ—Ü–µ–Ω–∫–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏. "
        "–û—Ç–≤–µ—á–∞–π –°–¢–†–û–ì–û —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–º –æ—Ç 0 –¥–æ 1 (–¥—Ä–æ–±–Ω–æ–µ —á–∏—Å–ª–æ —Å —Ç–æ—á–∫–æ–π), –Ω–∏—á–µ–≥–æ –∫—Ä–æ–º–µ —á–∏—Å–ª–∞. "
        "–ù–∏–∫–∞–∫–∏—Ö –æ–±—ä—è—Å–Ω–µ–Ω–∏–π, –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∏–ª–∏ –¥—Ä—É–≥–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤. "
        "–ï—Å–ª–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–ª–µ–∑–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ ‚Äî 0. –ï—Å–ª–∏ –æ—á–µ–Ω—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω ‚Äî 1."
    )

    for candidate in candidates:
        prompt = (
            f"–í–æ–ø—Ä–æ—Å: {query}\n\n"
            f"–¢–µ–∫—Å—Ç: {candidate['text']}\n\n"
            f"–û—Ü–µ–Ω–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ (0-1):"
        )
        try:
            resp = ollama.chat(
                model="mistral",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ]
            )
            score_str = resp['message']['content'].strip()
            score = float(score_str)
        except Exception as e:
            print(f"[!] –û—à–∏–±–∫–∞ –ø—Ä–∏ rerank: {e}")
            score = 0.0
        
        candidate_with_score = candidate.copy()
        candidate_with_score["score"] = score
        scored.append(candidate_with_score)
    
    scored_sorted = sorted(scored, key=lambda x: x["score"], reverse=True)
    return scored_sorted[:top_k]


def get_confidence(filtered: list[dict]) -> str:
    min_dist = min(r["distance"] for r in filtered)
    if min_dist < 0.35:
        return "üü¢ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: –≤—ã—Å–æ–∫–∞—è"
    elif min_dist < 0.55:
        return "üü° –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: —Å—Ä–µ–¥–Ω—è—è"
    else:
        return "üî¥ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: –Ω–∏–∑–∫–∞—è"

def build_context(filtered: list[dict]) -> tuple[str, list[dict]]:
    context_chunks = []
    token_total = 0
    used = []

    for r in filtered:
        tokens = count_tokens(r["text"])
        if token_total + tokens > MAX_TOKENS:
            break
        context_chunks.append(r["text"])
        token_total += tokens
        used.append({
            "page": r["page"],
            "id":   r["id"],
            "source": r["source"]
        })

    return "\n---\n".join(context_chunks), used

def search(query: str, top_k: int = 5) -> list[dict]:
    query_vec = embedder.encode(["query: " + query]).astype("float32")
    distances, ids = index.search(query_vec, top_k)

    results = []
    for idx, dist in zip(ids[0], distances[0]):
        meta = metadata[idx]
        results.append({
            "id":       idx,
            "distance": float(dist),
            "text":     meta.get("text", ""),
            "source":   meta.get("source", ""),
            "page":     meta.get("page", "?")
        })
    return results


def generate_answer(
    question: str,
    search_k: int = 10,
    rerank_k: int = 5
):
    try:
        results = search(question, top_k=search_k)
        reranked = rerank(question, results, top_k=rerank_k)

        if not reranked:
            print("üî¥ –ü–æ–¥—Ö–æ–¥—è—â–∏—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –û—Ç–≤–µ—Ç –Ω–µ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω.")
            return

        confidence = get_confidence(reranked)
        context, used_chunks = build_context(reranked)
        system = (
            "–¢—ã ‚Äî —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. "
            "–û—Ç–≤–µ—á–∞–π –æ–¥–Ω–∏–º –∞–±–∑–∞—Ü–µ–º, –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ —Å–≤—è–∑–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º ‚Äî **–Ω–∏–∫–∞–∫–∏—Ö —Å–ø–∏—Å–∫–æ–≤ –∏–ª–∏ –º–∞—Ä–∫–µ—Ä–æ–≤**. "
            "–ë–µ–∑ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, —Ç–æ–ª—å–∫–æ –æ—Ç–≤–µ—Ç."
        )
        prompt = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{context}\n\n–í–æ–ø—Ä–æ—Å: {question}\n\n–û—Ç–≤–µ—Ç:"

        resp = ollama.chat(
            model="mistral",
            messages=[
                {"role": "system", "content": system},
                {"role": "user",   "content": prompt}
            ]
        )
        answer = resp['message']['content'].strip()

        sources = [
            f"{chunk['source']} ‚Äî —Å—Ç—Ä. {chunk['page']}"
            for chunk in used_chunks
        ]

        return answer, confidence, sources

    except Exception:
        return (
            "[‚úó] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ LLM. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
            "üî¥ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞",
            []
        )


if __name__ == "__main__":
    q = input("–í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å: ")
    ans, conf, srcs = generate_answer(q)
    print(f"\nüîç –û—Ç–≤–µ—Ç ({conf}):\n{ans}\n")
    if srcs:
        print("üìö –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏:")
        for s in srcs:
            print(f"- {s}")


